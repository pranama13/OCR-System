{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOZGrk79v+3dAKtzQxX+jnb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranama13/OCR-System/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_Ll2fN8S9C6",
        "outputId": "de31e5b7-3b4b-42ac-c1d0-12eed5f3c6c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Collecting flask-cors\n",
            "  Downloading flask_cors-6.0.0-py3-none-any.whl.metadata (961 bytes)\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.2.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading flask_cors-6.0.0-py3-none-any.whl (11 kB)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pdf2image, flask-cors\n",
            "Successfully installed flask-cors-6.0.0 pdf2image-1.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow opencv-python-headless numpy flask flask-cors pdf2image pillow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y poppler-utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2IB9BLxS_Aw",
        "outputId": "0c5be72a-e136-4019-97db-0b4ba61d0668"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Waiting for headers] [W\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Waiting for headers] [W\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,683 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,966 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,944 kB]\n",
            "Get:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease [24.6 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,245 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,387 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,730 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,255 kB]\n",
            "Get:18 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [46.6 kB]\n",
            "Get:19 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 Packages [77.3 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,540 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,552 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.2 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Fetched 32.0 MB in 3s (11.2 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 91 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 697 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.8 [186 kB]\n",
            "Fetched 186 kB in 1s (200 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126102 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.8_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, Bidirectional, LSTM, Input, Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image\n",
        "from pdf2image import convert_from_path\n",
        "import logging\n",
        "import time"
      ],
      "metadata": {
        "id": "aYaQ5rkgTj7-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhGPyAuTWx1-",
        "outputId": "d8e086dc-5beb-477d-b296-f568c8aed643"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImagePreprocessor:\n",
        "    def __init__(self):\n",
        "        self.poppler_path = \"/usr/bin\"  # Poppler path in Colab after installation\n",
        "\n",
        "    def preprocess_image(self, image, resize_width=2400, resize_height=128):\n",
        "        if isinstance(image, Image.Image):\n",
        "            image = np.array(image)\n",
        "\n",
        "        if len(image.shape) == 3 and image.shape[2] > 1:\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        else:\n",
        "            gray = image\n",
        "\n",
        "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "        thresh = cv2.adaptiveThreshold(\n",
        "            blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "            cv2.THRESH_BINARY_INV, 11, 2\n",
        "        )\n",
        "        thresh = cv2.bitwise_not(thresh)\n",
        "        processed = cv2.resize(thresh, (resize_width, resize_height))\n",
        "        processed = processed / 255.0\n",
        "        processed = np.expand_dims(processed, axis=-1)\n",
        "        return processed\n",
        "\n",
        "    def deskew(self, image):\n",
        "        if len(image.shape) == 3 and image.shape[2] > 1:\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        else:\n",
        "            gray = image\n",
        "\n",
        "        coords = np.column_stack(np.where(gray > 0))\n",
        "        if len(coords) == 0:\n",
        "            return image\n",
        "\n",
        "        angle = cv2.minAreaRect(coords)[-1]\n",
        "        if angle < -45:\n",
        "            angle = -(90 + angle)\n",
        "        else:\n",
        "            angle = -angle\n",
        "\n",
        "        (h, w) = image.shape[:2]\n",
        "        center = (w // 2, h // 2)\n",
        "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "        rotated = cv2.warpAffine(\n",
        "            image, M, (w, h),\n",
        "            flags=cv2.INTER_CUBIC,\n",
        "            borderMode=cv2.BORDER_REPLICATE\n",
        "        )\n",
        "        return rotated\n",
        "\n",
        "    def remove_noise(self, image):\n",
        "        denoised = cv2.medianBlur(image, 3)\n",
        "        kernel = np.ones((1, 1), np.uint8)\n",
        "        denoised = cv2.morphologyEx(denoised, cv2.MORPH_OPEN, kernel)\n",
        "        return denoised\n",
        "\n",
        "    def pdf_to_images(self, pdf_path, dpi=300):\n",
        "        try:\n",
        "            images = convert_from_path(pdf_path, dpi=dpi, poppler_path=self.poppler_path)\n",
        "            image_arrays = []\n",
        "            for img in images:\n",
        "                img_array = np.array(img.convert('L'))\n",
        "                image_arrays.append(img_array)\n",
        "            return image_arrays\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Error converting PDF to images: {str(e)}\")"
      ],
      "metadata": {
        "id": "56BD0tD9XFWp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CTCDataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, images, labels, input_lengths, label_lengths, batch_size=32, datagen=None, shuffle=True, **kwargs):\n",
        "        super().__init__(**kwargs)  # Fix the warning\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.input_lengths = input_lengths\n",
        "        self.label_lengths = label_lengths\n",
        "        self.batch_size = batch_size\n",
        "        self.datagen = datagen\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(self.images))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.images) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start_idx = idx * self.batch_size\n",
        "        end_idx = min((idx + 1) * self.batch_size, len(self.images))\n",
        "        batch_indices = self.indices[start_idx:end_idx]\n",
        "\n",
        "        batch_images = self.images[batch_indices]\n",
        "        batch_labels = self.labels[batch_indices]\n",
        "        batch_input_lengths = self.input_lengths[batch_indices]\n",
        "        batch_label_lengths = self.label_lengths[batch_indices]\n",
        "\n",
        "        if self.datagen:\n",
        "            # Apply data augmentation\n",
        "            augmented_images = []\n",
        "            for img in batch_images:\n",
        "                img_expanded = np.expand_dims(img, axis=0)\n",
        "                augmented = next(self.datagen.flow(img_expanded, batch_size=1))\n",
        "                augmented_images.append(augmented[0])\n",
        "            batch_images = np.array(augmented_images)\n",
        "\n",
        "        print(f\"Debug - CTCDataGenerator: batch_images shape={batch_images.shape}, batch_labels shape={batch_labels.shape}, \"\n",
        "              f\"batch_input_lengths shape={batch_input_lengths.shape}, batch_label_lengths shape={batch_label_lengths.shape}\")\n",
        "\n",
        "        return (\n",
        "            {\n",
        "                'input_image': batch_images,\n",
        "                'labels': batch_labels,\n",
        "                'input_length': batch_input_lengths,\n",
        "                'label_length': batch_label_lengths\n",
        "            },\n",
        "            np.zeros(len(batch_images))  # Dummy targets since loss is computed in CTCLayer\n",
        "        )\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n"
      ],
      "metadata": {
        "id": "yzobPpbIXHLt"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OCRModel:\n",
        "    def __init__(self, model_path=None):\n",
        "        self.model = None\n",
        "        self.model_path = model_path\n",
        "        self.input_shape = (128, 2400, 1)  # Updated input shape\n",
        "        self.char_list = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz \"\n",
        "        self.num_classes = len(self.char_list) + 1\n",
        "        self.max_label_length = 300  # Define max label length as a class attribute\n",
        "        self.MODELS_FOLDER = \"/content/models\"\n",
        "        os.makedirs(self.MODELS_FOLDER, exist_ok=True)\n",
        "\n",
        "        if model_path and os.path.exists(model_path):\n",
        "            self.load_model(model_path)\n",
        "        else:\n",
        "            self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        input_image = tf.keras.layers.Input(shape=self.input_shape, name='input_image', dtype='float32')\n",
        "        # Fixed: Use None for variable sequence length - CTC expects 2D (batch_size, sequence_length)\n",
        "        labels = tf.keras.layers.Input(name='labels', shape=(None,), dtype='int32')\n",
        "        input_length = tf.keras.layers.Input(name='input_length', shape=[1], dtype='int64')\n",
        "        label_length = tf.keras.layers.Input(name='label_length', shape=[1], dtype='int64')\n",
        "\n",
        "        x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_image)\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "\n",
        "        new_shape = ((self.input_shape[1] // 2), (self.input_shape[0] // 2) * 128)\n",
        "        x = tf.keras.layers.Reshape(target_shape=new_shape)(x)\n",
        "\n",
        "        x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
        "        x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
        "\n",
        "        predictions = Dense(self.num_classes, activation='softmax', name='dense_output')(x)\n",
        "\n",
        "        # Create the CTC layer with explicit input handling\n",
        "        ctc_layer = CTCLayer(name='ctc_loss')\n",
        "        ctc_layer.num_classes = self.num_classes  # Pass num_classes to the layer\n",
        "        output = ctc_layer([predictions, labels, input_length, label_length])\n",
        "\n",
        "        self.model = Model(\n",
        "            inputs=[input_image, labels, input_length, label_length],\n",
        "            outputs=output\n",
        "        )\n",
        "\n",
        "        self.model.compile(optimizer=Adam(learning_rate=0.001))\n",
        "        self.model.summary()\n",
        "        print(f\"Model built with input shape: {self.input_shape}, expected time steps: {self.input_shape[1] // 2}\")\n",
        "\n",
        "    def preprocess_image(self, image):\n",
        "        try:\n",
        "            if image is None:\n",
        "                raise ValueError(\"Image is None after loading\")\n",
        "\n",
        "            aspect_ratio = image.shape[1] / image.shape[0]\n",
        "            new_width = int(self.input_shape[0] * aspect_ratio)\n",
        "            image = cv2.resize(image, (new_width, self.input_shape[0]))\n",
        "\n",
        "            if new_width < self.input_shape[1]:\n",
        "                pad_width = self.input_shape[1] - new_width\n",
        "                image = np.pad(image, ((0, 0), (0, pad_width)), mode='constant', constant_values=0)\n",
        "            else:\n",
        "                image = cv2.resize(image, (self.input_shape[1], self.input_shape[0]))\n",
        "\n",
        "            if len(image.shape) == 2:\n",
        "                image = image.reshape(self.input_shape[0], self.input_shape[1], 1)\n",
        "\n",
        "            return image\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Failed to preprocess image: {str(e)}\")\n",
        "\n",
        "    def load_data(self, data_dir, max_label_length=300):\n",
        "        image_dir = os.path.join(data_dir, 'images')\n",
        "        label_file = os.path.join(data_dir, 'labels.txt')\n",
        "\n",
        "        if not os.path.exists(image_dir):\n",
        "            raise ValueError(f\"Image directory does not exist: {image_dir}\")\n",
        "        if not os.path.exists(label_file):\n",
        "            raise ValueError(f\"Label file does not exist: {label_file}\")\n",
        "\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        with open(label_file, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    img_name, text = line.split(' ', 1)\n",
        "                    img_path = os.path.join(image_dir, img_name)\n",
        "\n",
        "                    if not os.path.exists(img_path):\n",
        "                        print(f\"Warning: Image not found - {img_path}\")\n",
        "                        continue\n",
        "\n",
        "                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "                    if img is None:\n",
        "                        print(f\"Warning: Failed to load image - {img_path}\")\n",
        "                        continue\n",
        "\n",
        "                    try:\n",
        "                        img = self.preprocess_image(img)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Warning: Failed to preprocess image {img_path}: {str(e)}\")\n",
        "                        continue\n",
        "\n",
        "                    label = []\n",
        "                    for c in text[:max_label_length]:\n",
        "                        if c in self.char_list:\n",
        "                            label.append(self.char_list.index(c))\n",
        "                        else:\n",
        "                            print(f\"Warning: Character '{c}' not in char_list, skipping\")\n",
        "\n",
        "                    if not label:\n",
        "                        print(f\"Warning: Empty label for image {img_path}\")\n",
        "                        continue\n",
        "\n",
        "                    images.append(img)\n",
        "                    labels.append(label)\n",
        "                    print(f\"Debug - Loaded image {img_name}, label length: {len(label)}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Warning: Error processing line '{line}': {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "        if not images:\n",
        "            raise ValueError(\"No valid images/labels loaded\")\n",
        "\n",
        "        return np.array(images), labels\n",
        "\n",
        "    def train(self, train_data_dir, validation_data_dir, epochs=50, batch_size=32):\n",
        "        train_images, train_labels = self.load_data(train_data_dir, max_label_length=self.max_label_length)\n",
        "        val_images, val_labels = self.load_data(validation_data_dir, max_label_length=self.max_label_length)\n",
        "\n",
        "        train_images = train_images.astype('float32') / 255.0\n",
        "        val_images = val_images.astype('float32') / 255.0\n",
        "\n",
        "        print(f\"Debug - Train label lengths: {[len(l) for l in train_labels]}\")\n",
        "        print(f\"Debug - Val label lengths: {[len(l) for l in val_labels]}\")\n",
        "\n",
        "        max_length = max(max(len(l) for l in train_labels), max(len(l) for l in val_labels))\n",
        "        print(f\"Debug - Max label length: {max_length}\")\n",
        "        train_labels_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "            train_labels, maxlen=self.max_label_length, padding='post', value=-1\n",
        "        )\n",
        "        val_labels_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "            val_labels, maxlen=self.max_label_length, padding='post', value=-1\n",
        "        )\n",
        "\n",
        "        train_input_lengths = np.ones((len(train_images), 1), dtype=np.int64) * (self.input_shape[1] // 2)\n",
        "        val_input_lengths = np.ones((len(val_images), 1), dtype=np.int64) * (self.input_shape[1] // 2)\n",
        "\n",
        "        train_label_lengths = np.array([len(label) for label in train_labels], dtype=np.int64).reshape(-1, 1)\n",
        "        val_label_lengths = np.array([len(label) for label in val_labels], dtype=np.int64).reshape(-1, 1)\n",
        "\n",
        "        print(f\"Debug - train_images shape: {train_images.shape}\")\n",
        "        print(f\"Debug - train_labels_padded shape: {train_labels_padded.shape}\")\n",
        "        print(f\"Debug - train_input_lengths shape: {train_input_lengths.shape}\")\n",
        "        print(f\"Debug - train_label_lengths shape: {train_label_lengths.shape}\")\n",
        "        print(f\"Debug - val_images shape: {val_images.shape}\")\n",
        "        print(f\"Debug - val_labels_padded shape: {val_labels_padded.shape}\")\n",
        "        print(f\"Debug - val_input_lengths shape: {val_input_lengths.shape}\")\n",
        "        print(f\"Debug - val_label_lengths shape: {val_label_lengths.shape}\")\n",
        "\n",
        "        available_time_steps = self.input_shape[1] // 2\n",
        "        max_label_length = max(np.max(train_label_lengths), np.max(val_label_lengths))\n",
        "        if max_label_length > available_time_steps:\n",
        "            raise ValueError(\n",
        "                f\"Label length too long for model output. Max label length: {max_label_length}, \"\n",
        "                f\"Available time steps: {available_time_steps}. Consider increasing model time steps.\"\n",
        "            )\n",
        "\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            rotation_range=10,\n",
        "            width_shift_range=0.1,\n",
        "            height_shift_range=0.1,\n",
        "            shear_range=0.1,\n",
        "            zoom_range=0.1,\n",
        "            fill_mode='nearest'\n",
        "        )\n",
        "\n",
        "        validation_datagen = ImageDataGenerator()\n",
        "\n",
        "        train_generator = CTCDataGenerator(\n",
        "            images=train_images,\n",
        "            labels=train_labels_padded,\n",
        "            input_lengths=train_input_lengths,\n",
        "            label_lengths=train_label_lengths,\n",
        "            batch_size=batch_size,\n",
        "            datagen=train_datagen,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "        val_generator = CTCDataGenerator(\n",
        "            images=val_images,\n",
        "            labels=val_labels_padded,\n",
        "            input_lengths=val_input_lengths,\n",
        "            label_lengths=val_label_lengths,\n",
        "            batch_size=batch_size,\n",
        "            datagen=validation_datagen,\n",
        "            shuffle=False\n",
        "        )\n",
        "\n",
        "        callbacks_list = [\n",
        "            tf.keras.callbacks.ModelCheckpoint(\n",
        "                filepath=os.path.join(self.MODELS_FOLDER, 'model_checkpoint.h5'),\n",
        "                save_best_only=True,\n",
        "                monitor='val_loss'\n",
        "            ),\n",
        "            tf.keras.callbacks.EarlyStopping(\n",
        "                monitor='val_loss',\n",
        "                patience=10,\n",
        "                restore_best_weights=True\n",
        "            ),\n",
        "            tf.keras.callbacks.ReduceLROnPlateau(\n",
        "                monitor='val_loss',\n",
        "                factor=0.2,\n",
        "                patience=5,\n",
        "                min_lr=0.00001\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        if self.model is None:\n",
        "            self.build_model()\n",
        "\n",
        "        steps_per_epoch = max(1, len(train_images) // batch_size)\n",
        "        validation_steps = max(1, len(val_images) // batch_size)\n",
        "\n",
        "        history = self.model.fit(\n",
        "            train_generator,\n",
        "            steps_per_epoch=steps_per_epoch,\n",
        "            validation_data=val_generator,\n",
        "            validation_steps=validation_steps,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks_list,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        self.save_model(os.path.join(self.MODELS_FOLDER, 'ocr_model.h5'))\n",
        "        return history\n",
        "\n",
        "    def predict(self, image):\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model not initialized. Please build or load a model first.\")\n",
        "\n",
        "        processed_image = self.preprocess_image(image)\n",
        "        processed_image = processed_image.astype('float32') / 255.0\n",
        "        processed_image = processed_image.reshape(1, self.input_shape[0], self.input_shape[1], 1)\n",
        "\n",
        "        input_length = np.ones((1, 1), dtype=np.int64) * (self.input_shape[1] // 2)\n",
        "        label_length = np.zeros((1, 1), dtype=np.int64)\n",
        "\n",
        "        prediction = self.model.predict(\n",
        "            {\n",
        "                'input_image': processed_image,\n",
        "                'labels': np.zeros((1, self.max_label_length), dtype=np.int32),\n",
        "                'input_length': input_length,\n",
        "                'label_length': label_length\n",
        "            },\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        text = self._decode_prediction(prediction)\n",
        "        return text\n",
        "\n",
        "    def _decode_prediction(self, prediction):\n",
        "        input_length = np.ones(prediction.shape[0], dtype=np.int64) * prediction.shape[1]\n",
        "        decoded, _ = tf.keras.backend.ctc_decode(\n",
        "            prediction, input_length=input_length, greedy=True\n",
        "        )\n",
        "        decoded = decoded[0][0].numpy()\n",
        "        text = \"\"\n",
        "        for i in decoded:\n",
        "            if i != -1 and i < len(self.char_list):\n",
        "                text += self.char_list[i]\n",
        "        return text\n",
        "\n",
        "    def save_model(self, path):\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"No model to save\")\n",
        "\n",
        "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "        self.model.save(path)\n",
        "        print(f\"Model saved to {path}\")\n",
        "\n",
        "    def load_model(self, path):\n",
        "        if not os.path.exists(path):\n",
        "            raise FileNotFoundError(f\"Model file not found: {path}\")\n",
        "\n",
        "        self.model = tf.keras.models.load_model(\n",
        "            path,\n",
        "            custom_objects={'CTCLayer': CTCLayer}\n",
        "        )\n",
        "        print(f\"Model loaded from {path}\")\n"
      ],
      "metadata": {
        "id": "VUxEXuG8XLdD"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OCRService:\n",
        "    def __init__(self, model_path=None):\n",
        "        self.model = OCRModel(model_path)\n",
        "        self.preprocessor = ImagePreprocessor()\n",
        "\n",
        "    def process_image(self, image_path):\n",
        "        try:\n",
        "            if not os.path.exists(image_path):\n",
        "                return {'status': 'error', 'message': f'File not found: {image_path}'}\n",
        "\n",
        "            image = cv2.imread(image_path)\n",
        "            if image is None:\n",
        "                return {'status': 'error', 'message': f'Failed to load image: {image_path}'}\n",
        "\n",
        "            processed_image = self.preprocessor.preprocess_image(image)\n",
        "            start_time = time.time()\n",
        "            text = self.model.predict(processed_image)\n",
        "            processing_time = time.time() - start_time\n",
        "\n",
        "            return {\n",
        "                'status': 'success',\n",
        "                'text': text,\n",
        "                'processing_time': processing_time,\n",
        "                'file_path': image_path\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {'status': 'error', 'message': f'Error processing image: {str(e)}'}\n",
        "\n",
        "    def train_model(self, training_data_dir, validation_data_dir, epochs=50, batch_size=32):\n",
        "        try:\n",
        "            if not os.path.exists(training_data_dir):\n",
        "                return {'status': 'error', 'message': f'Training data directory not found: {training_data_dir}'}\n",
        "\n",
        "            if not os.path.exists(validation_data_dir):\n",
        "                return {'status': 'error', 'message': f'Validation data directory not found: {validation_data_dir}'}\n",
        "\n",
        "            start_time = time.time()\n",
        "            history = self.model.train(\n",
        "                training_data_dir,\n",
        "                validation_data_dir,\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size\n",
        "            )\n",
        "            training_time = time.time() - start_time\n",
        "\n",
        "            history_dict = {}\n",
        "            for key, value in history.history.items():\n",
        "                history_dict[key] = [float(v) for v in value]\n",
        "\n",
        "            return {\n",
        "                'status': 'success',\n",
        "                'training_time': training_time,\n",
        "                'epochs_completed': len(history_dict.get('loss', [])),\n",
        "                'final_loss': history_dict.get('loss', [0])[-1],\n",
        "                'final_val_loss': history_dict.get('val_loss', [0])[-1],\n",
        "                'history': history_dict\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {'status': 'error', 'message': f'Error training model: {str(e)}'}"
      ],
      "metadata": {
        "id": "Dv9uic5fXV8X"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/My Drive/OCR/train_data\" /content/train_data\n",
        "!cp -r \"/content/drive/My Drive/OCR/val_data\" /content/val_data"
      ],
      "metadata": {
        "id": "PADp5oZ7XZen"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = \"/content/train_data\"\n",
        "val_data_dir = \"/content/val_data\"\n",
        "\n",
        "# Initialize the OCR service\n",
        "ocr_service = OCRService()\n",
        "\n",
        "# Train the model\n",
        "result = ocr_service.train_model(\n",
        "    training_data_dir=train_data_dir,\n",
        "    validation_data_dir=val_data_dir,\n",
        "    epochs=50,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Print training results\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1l5CaFOHXl2E",
        "outputId": "0504ac79-2db2-4e82-ae29-342998a06dab"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_image         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m2400\u001b[0m, │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_45 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m2400\u001b[0m, │        \u001b[38;5;34m320\u001b[0m │ input_image[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_15    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1200\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ conv2d_45[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_46 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1200\u001b[0m,  │     \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d_15… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_47 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1200\u001b[0m,  │     \u001b[38;5;34m73,856\u001b[0m │ conv2d_46[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1200\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ conv2d_47[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mReshape\u001b[0m)           │ \u001b[38;5;34m8192\u001b[0m)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_30    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1200\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m8,520,704\u001b[0m │ reshape_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_31    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1200\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m164,352\u001b[0m │ bidirectional_30… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1200\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │      \u001b[38;5;34m8,256\u001b[0m │ bidirectional_31… │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ labels (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_length        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ label_length        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ ctc_loss (\u001b[38;5;33mCTCLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1200\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ dense_output[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ labels[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                     │                   │            │ input_length[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │                   │            │ label_length[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_image         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2400</span>, │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2400</span>, │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_image[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_15    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1200</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1200</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d_15… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1200</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ conv2d_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1200</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_30    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">8,520,704</span> │ reshape_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_31    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │ bidirectional_30… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ bidirectional_31… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ labels (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_length        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ label_length        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ ctc_loss (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CTCLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_output[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ labels[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                     │                   │            │ input_length[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │                   │            │ label_length[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,785,984\u001b[0m (33.52 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,785,984</span> (33.52 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,785,984\u001b[0m (33.52 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,785,984</span> (33.52 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model built with input shape: (128, 2400, 1), expected time steps: 1200\n",
            "Debug - Loaded image sample1.png, label length: 138\n",
            "Debug - Loaded image sample2.png, label length: 296\n",
            "Debug - Loaded image sample3.png, label length: 296\n",
            "Debug - Loaded image sample4.png, label length: 296\n",
            "Debug - Loaded image sample5.png, label length: 296\n",
            "Debug - Loaded image sample6.png, label length: 138\n",
            "Debug - Loaded image sample7.png, label length: 138\n",
            "Debug - Loaded image sample8.png, label length: 138\n",
            "Debug - Loaded image sample9.png, label length: 296\n",
            "Debug - Loaded image sample10.png, label length: 138\n",
            "Debug - Loaded image sample11.png, label length: 277\n",
            "Debug - Loaded image sample12.png, label length: 296\n",
            "Debug - Loaded image sample13.png, label length: 277\n",
            "Debug - Loaded image sample14.png, label length: 258\n",
            "Debug - Loaded image sample15.png, label length: 296\n",
            "Debug - Loaded image sample16.png, label length: 296\n",
            "Debug - Loaded image sample17.png, label length: 258\n",
            "Debug - Loaded image sample18.png, label length: 296\n",
            "Debug - Loaded image sample19.png, label length: 296\n",
            "Debug - Loaded image sample20.png, label length: 258\n",
            "Debug - Loaded image sample21.png, label length: 258\n",
            "Debug - Loaded image sample22.png, label length: 258\n",
            "Debug - Loaded image sample23.png, label length: 258\n",
            "Debug - Loaded image sample24.png, label length: 258\n",
            "Debug - Loaded image sample25.png, label length: 258\n",
            "Debug - Loaded image sample26.png, label length: 138\n",
            "Debug - Loaded image sample27.png, label length: 258\n",
            "Debug - Loaded image sample28.png, label length: 138\n",
            "Debug - Loaded image sample29.png, label length: 296\n",
            "Debug - Loaded image sample30.png, label length: 258\n",
            "Debug - Loaded image sample31.png, label length: 296\n",
            "Debug - Loaded image sample32.png, label length: 296\n",
            "Debug - Loaded image val_sample1.png, label length: 258\n",
            "Debug - Loaded image val_sample2.png, label length: 300\n",
            "Debug - Loaded image val_sample3.png, label length: 300\n",
            "Debug - Loaded image val_sample4.png, label length: 300\n",
            "Debug - Loaded image val_sample5.png, label length: 258\n",
            "Debug - Loaded image val_sample6.png, label length: 147\n",
            "Debug - Loaded image val_sample7.png, label length: 164\n",
            "Debug - Loaded image val_sample8.png, label length: 216\n",
            "Debug - Train label lengths: [138, 296, 296, 296, 296, 138, 138, 138, 296, 138, 277, 296, 277, 258, 296, 296, 258, 296, 296, 258, 258, 258, 258, 258, 258, 138, 258, 138, 296, 258, 296, 296]\n",
            "Debug - Val label lengths: [258, 300, 300, 300, 258, 147, 164, 216]\n",
            "Debug - Max label length: 300\n",
            "Debug - train_images shape: (32, 128, 2400, 1)\n",
            "Debug - train_labels_padded shape: (32, 300)\n",
            "Debug - train_input_lengths shape: (32, 1)\n",
            "Debug - train_label_lengths shape: (32, 1)\n",
            "Debug - val_images shape: (8, 128, 2400, 1)\n",
            "Debug - val_labels_padded shape: (8, 300)\n",
            "Debug - val_input_lengths shape: (8, 1)\n",
            "Debug - val_label_lengths shape: (8, 1)\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "Epoch 1/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24s/step - loss: 4086.8970Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n",
            "Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29s/step - loss: 4086.8970 - val_loss: 4085.8237 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 4083.9302Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - loss: 4083.9302 - val_loss: 4061.7515 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 4063.4458Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 4063.4458 - val_loss: 3917.3271 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - loss: 3950.3000Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - loss: 3950.3000 - val_loss: 3655.5972 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 3668.2700Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - loss: 3668.2700 - val_loss: 3495.6416 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 3499.4956Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - loss: 3499.4956 - val_loss: 3438.1594 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - loss: 3439.5479Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - loss: 3439.5479 - val_loss: 3414.5266 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 3416.1128Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 3416.1128 - val_loss: 3403.7126 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 3405.1147Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - loss: 3405.1147 - val_loss: 3398.6892 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - loss: 3400.1116Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - loss: 3400.1116 - val_loss: 3396.2788 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - loss: 3397.7422Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - loss: 3397.7422 - val_loss: 3395.0266 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - loss: 3396.4795Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - loss: 3396.4795 - val_loss: 3394.3118 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 3395.7671Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 3395.7671 - val_loss: 3393.8665 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 3395.3252Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 3395.3252 - val_loss: 3393.5728 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 3395.0337Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 3395.0337 - val_loss: 3393.3623 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - loss: 3394.8230Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - loss: 3394.8230 - val_loss: 3393.2104 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - loss: 3394.6743Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - loss: 3394.6743 - val_loss: 3393.0928 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 3394.5571Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - loss: 3394.5571 - val_loss: 3393.0066 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15s/step - loss: 3394.4705Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step - loss: 3394.4705 - val_loss: 3392.9331 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - loss: 3394.3987Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - loss: 3394.3987 - val_loss: 3392.8828 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - loss: 3394.3506Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - loss: 3394.3506 - val_loss: 3392.8384 - learning_rate: 0.0010\n",
            "Epoch 22/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - loss: 3394.3052Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - loss: 3394.3052 - val_loss: 3392.8005 - learning_rate: 0.0010\n",
            "Epoch 23/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - loss: 3394.2671Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - loss: 3394.2671 - val_loss: 3392.7695 - learning_rate: 0.0010\n",
            "Epoch 24/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 3394.2368Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 3394.2368 - val_loss: 3392.7458 - learning_rate: 0.0010\n",
            "Epoch 25/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 3394.2107Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 3394.2107 - val_loss: 3392.7251 - learning_rate: 0.0010\n",
            "Epoch 26/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18s/step - loss: 3394.1899Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - loss: 3394.1899 - val_loss: 3392.7085 - learning_rate: 0.0010\n",
            "Epoch 27/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - loss: 3394.1748Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22s/step - loss: 3394.1748 - val_loss: 3392.6924 - learning_rate: 0.0010\n",
            "Epoch 28/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15s/step - loss: 3394.1592Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step - loss: 3394.1592 - val_loss: 3392.6807 - learning_rate: 0.0010\n",
            "Epoch 29/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 3394.1465Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 3394.1465 - val_loss: 3392.6680 - learning_rate: 0.0010\n",
            "Epoch 30/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 3394.1348Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 3394.1348 - val_loss: 3392.6582 - learning_rate: 0.0010\n",
            "Epoch 31/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18s/step - loss: 3394.1245Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - loss: 3394.1245 - val_loss: 3392.6475 - learning_rate: 0.0010\n",
            "Epoch 32/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - loss: 3394.1147Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - loss: 3394.1147 - val_loss: 3392.6401 - learning_rate: 0.0010\n",
            "Epoch 33/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - loss: 3394.1077Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - loss: 3394.1077 - val_loss: 3392.6331 - learning_rate: 0.0010\n",
            "Epoch 34/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 3394.1011Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - loss: 3394.1011 - val_loss: 3392.6274 - learning_rate: 0.0010\n",
            "Epoch 35/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 3394.0952Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 3394.0952 - val_loss: 3392.6172 - learning_rate: 0.0010\n",
            "Epoch 36/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 3394.0867Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 3394.0867 - val_loss: 3392.6123 - learning_rate: 0.0010\n",
            "Epoch 37/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 3394.0825Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 3394.0825 - val_loss: 3392.6074 - learning_rate: 0.0010\n",
            "Epoch 38/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18s/step - loss: 3394.0781Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23s/step - loss: 3394.0781 - val_loss: 3392.6040 - learning_rate: 0.0010\n",
            "Epoch 39/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15s/step - loss: 3394.0752Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18s/step - loss: 3394.0752 - val_loss: 3392.5977 - learning_rate: 0.0010\n",
            "Epoch 40/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - loss: 3394.0688Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - loss: 3394.0688 - val_loss: 3392.5945 - learning_rate: 0.0010\n",
            "Epoch 41/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - loss: 3394.0654Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - loss: 3394.0654 - val_loss: 3392.5918 - learning_rate: 0.0010\n",
            "Epoch 42/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 3394.0632Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 3394.0632 - val_loss: 3392.5898 - learning_rate: 0.0010\n",
            "Epoch 43/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - loss: 3394.0613Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - loss: 3394.0613 - val_loss: 3392.5869 - learning_rate: 0.0010\n",
            "Epoch 44/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - loss: 3394.0579Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - loss: 3394.0579 - val_loss: 3392.5847 - learning_rate: 0.0010\n",
            "Epoch 45/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - loss: 3394.0552Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20s/step - loss: 3394.0552 - val_loss: 3392.5825 - learning_rate: 0.0010\n",
            "Epoch 46/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 3394.0542Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 3394.0542 - val_loss: 3392.5811 - learning_rate: 0.0010\n",
            "Epoch 47/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - loss: 3394.0518Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21s/step - loss: 3394.0518 - val_loss: 3392.5798 - learning_rate: 0.0010\n",
            "Epoch 48/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 3394.0508Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - loss: 3394.0508 - val_loss: 3392.5767 - learning_rate: 0.0010\n",
            "Epoch 49/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 3394.0471Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step - loss: 3394.0471 - val_loss: 3392.5750 - learning_rate: 0.0010\n",
            "Epoch 50/50\n",
            "Debug - CTCDataGenerator: batch_images shape=(32, 128, 2400, 1), batch_labels shape=(32, 300), batch_input_lengths shape=(32, 1), batch_label_lengths shape=(32, 1)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 3394.0457Debug - CTCDataGenerator: batch_images shape=(8, 128, 2400, 1), batch_labels shape=(8, 300), batch_input_lengths shape=(8, 1), batch_label_lengths shape=(8, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16s/step - loss: 3394.0457 - val_loss: 3392.5737 - learning_rate: 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/models/ocr_model.h5\n",
            "{'status': 'success', 'training_time': 881.2608993053436, 'epochs_completed': 50, 'final_loss': 3394.045654296875, 'final_val_loss': 3392.57373046875, 'history': {'loss': [4086.89697265625, 4083.93017578125, 4063.44580078125, 3950.300048828125, 3668.27001953125, 3499.49560546875, 3439.5478515625, 3416.11279296875, 3405.11474609375, 3400.111572265625, 3397.7421875, 3396.4794921875, 3395.76708984375, 3395.3251953125, 3395.03369140625, 3394.822998046875, 3394.67431640625, 3394.55712890625, 3394.470458984375, 3394.398681640625, 3394.3505859375, 3394.30517578125, 3394.26708984375, 3394.23681640625, 3394.210693359375, 3394.18994140625, 3394.1748046875, 3394.1591796875, 3394.146484375, 3394.134765625, 3394.12451171875, 3394.11474609375, 3394.107666015625, 3394.10107421875, 3394.09521484375, 3394.086669921875, 3394.08251953125, 3394.078125, 3394.0751953125, 3394.06884765625, 3394.0654296875, 3394.063232421875, 3394.061279296875, 3394.057861328125, 3394.05517578125, 3394.05419921875, 3394.0517578125, 3394.05078125, 3394.047119140625, 3394.045654296875], 'val_loss': [4085.82373046875, 4061.75146484375, 3917.3271484375, 3655.59716796875, 3495.6416015625, 3438.159423828125, 3414.526611328125, 3403.712646484375, 3398.689208984375, 3396.27880859375, 3395.026611328125, 3394.311767578125, 3393.866455078125, 3393.57275390625, 3393.3623046875, 3393.21044921875, 3393.0927734375, 3393.006591796875, 3392.93310546875, 3392.8828125, 3392.83837890625, 3392.800537109375, 3392.76953125, 3392.745849609375, 3392.72509765625, 3392.70849609375, 3392.6923828125, 3392.6806640625, 3392.66796875, 3392.658203125, 3392.6474609375, 3392.64013671875, 3392.633056640625, 3392.62744140625, 3392.6171875, 3392.6123046875, 3392.607421875, 3392.60400390625, 3392.59765625, 3392.594482421875, 3392.591796875, 3392.58984375, 3392.5869140625, 3392.584716796875, 3392.58251953125, 3392.5810546875, 3392.579833984375, 3392.57666015625, 3392.574951171875, 3392.57373046875], 'learning_rate': [0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513, 0.0010000000474974513]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the model file\n",
        "files.download('/content/models/ocr_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "JPZRBfNUqpSJ",
        "outputId": "04c418b0-50c4-468e-ae2d-8bb7de58ae18"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7d5cc3b8-2aa5-43a8-a80f-740bfb952f07\", \"ocr_model.h5\", 105515408)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CTCLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, name=None):\n",
        "        super().__init__(name=name)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        y_pred, labels, input_length, label_length = inputs\n",
        "\n",
        "        # Squeeze the length tensors to remove extra dimensions\n",
        "        input_length = tf.cast(tf.squeeze(input_length, axis=-1), tf.int32)\n",
        "        label_length = tf.cast(tf.squeeze(label_length, axis=-1), tf.int32)\n",
        "\n",
        "        # Ensure labels is int32\n",
        "        labels = tf.cast(labels, tf.int32)\n",
        "\n",
        "        # Convert predictions to log probabilities for CTC\n",
        "        y_pred = tf.nn.log_softmax(y_pred, axis=-1)\n",
        "\n",
        "        # Use tf.nn.ctc_loss instead of tf.keras.backend.ctc_batch_cost\n",
        "        loss = tf.nn.ctc_loss(\n",
        "            labels=labels,\n",
        "            logits=y_pred,\n",
        "            label_length=label_length,\n",
        "            logit_length=input_length,\n",
        "            logits_time_major=False,\n",
        "            blank_index=self.num_classes-1 if hasattr(self, 'num_classes') else 63\n",
        "        )\n",
        "\n",
        "        # Add loss to the layer\n",
        "        self.add_loss(tf.reduce_mean(loss))\n",
        "\n",
        "        # Return predictions (convert back from log space)\n",
        "        return tf.nn.softmax(y_pred, axis=-1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0]"
      ],
      "metadata": {
        "id": "MMemwm51lmqk"
      },
      "execution_count": 50,
      "outputs": []
    }
  ]
}